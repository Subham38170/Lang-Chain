{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "829d33aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from IPython.display import Markdown\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(r'D:\\AI ML\\aimlvenv\\Scripts\\active')\n",
    "groq_api_key = os.getenv('GROQ_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6620ab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ssahu\\AppData\\Roaming\\Python\\Python313\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "model = ChatGroq(model='openai/gpt-oss-120b',api_key=groq_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c32a0953",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hello Subham! üëã It's great to meet you. Welcome to the world of learning‚Äîthere's so much exciting stuff to explore. \\n\\nWhat topics or skills are you interested in diving into? Whether it‚Äôs programming, math, science, languages, or something completely different, I‚Äôm here to help you along the way. Feel free to ask any questions or let me know what you‚Äôd like to focus on first!\", additional_kwargs={'reasoning_content': 'The user says \"Hi, My name is Subham and i am learner\". They are introducing themselves. We should respond friendly, maybe ask about what they want to learn, etc. There\\'s no disallowed content. So respond as ChatGPT, friendly.'}, response_metadata={'token_usage': {'completion_tokens': 146, 'prompt_tokens': 82, 'total_tokens': 228, 'completion_time': 0.377335438, 'prompt_time': 0.004013087, 'queue_time': 0.049303693, 'total_time': 0.381348525, 'completion_tokens_details': {'reasoning_tokens': 52}}, 'model_name': 'openai/gpt-oss-120b', 'system_fingerprint': 'fp_a28df4bce5', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019b12ae-d29a-7fb3-a5f6-90ce563a1f28-0', usage_metadata={'input_tokens': 82, 'output_tokens': 146, 'total_tokens': 228})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage,AIMessage\n",
    "model.invoke([HumanMessage('Hi, My name is Subham and i am learner')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "067ff091",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Your name is **Subham**, and you‚Äôve mentioned that you‚Äôre a **learner**‚Äîsomeone who‚Äôs actively studying or picking up new skills. If you‚Äôd like to share more about the specific subjects or projects you‚Äôre working on, I‚Äôm happy to dive in and help you out!', additional_kwargs={'reasoning_content': 'The user asks \"Hey what is my name and what i do\". We have prior conversation: user introduced as Subham and said \"I am a learner\". So answer: name Subham, a learner. Possibly ask what they do. The user asks \"what i do\". We can answer based on info: they are a learner. Could ask for clarification. Provide response.'}, response_metadata={'token_usage': {'completion_tokens': 146, 'prompt_tokens': 145, 'total_tokens': 291, 'completion_time': 0.346612563, 'prompt_time': 0.00845398, 'queue_time': 0.04916832, 'total_time': 0.355066543, 'completion_tokens_details': {'reasoning_tokens': 77}}, 'model_name': 'openai/gpt-oss-120b', 'system_fingerprint': 'fp_fd1fe7f861', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019b12ae-d5b2-7270-8f95-d8d0cd18a336-0', usage_metadata={'input_tokens': 145, 'output_tokens': 146, 'total_tokens': 291})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke([\n",
    "    HumanMessage('Hi, My name is Subham and I am a learner'),\n",
    "    AIMessage('Hello Subham! üëã Great to meet you. I‚Äôm glad you‚Äôre here learning‚Äîwhat topics or skills are you diving into right now? Let me know how I can help you on your learning journey!'),\n",
    "    HumanMessage('Hey what is my name and what i do')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbbe116a",
   "metadata": {},
   "source": [
    "### Message History\n",
    "We can user a Message History class to wrap our model and make it stateful. This will keep track of inputs and outputs of the model, and store them in some datastore. Future intercations will then load those messages and pass them into the chain as part of the inpput."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76f2ab33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory \n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "store = {}\n",
    "\n",
    "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "    return store[session_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a497a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {'configurable':{'session_id':'chat1'}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d894b4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history = RunnableWithMessageHistory(model,get_session_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d966a96c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello Subham! üëã\\n\\nGreat to meet you. It‚Äôs wonderful that you‚Äôre on a learning journey‚Äîthere‚Äôs so much to explore! \\n\\nWhat topics or skills are you interested in diving into? Whether it‚Äôs programming, math, science, languages, art, or anything else, I‚Äôm here to help you find resources, answer questions, or work through problems together. Let me know what you‚Äôd like to focus on, and we‚Äôll get started!', additional_kwargs={'reasoning_content': 'We need to respond as ChatGPT. The user introduced themselves: \"Hi, My name is Subham and I amn a learner\". Likely they want a greeting, perhaps ask how we can help. We can ask about their interests, what they want to learn. Should be friendly.'}, response_metadata={'token_usage': {'completion_tokens': 163, 'prompt_tokens': 84, 'total_tokens': 247, 'completion_time': 0.398705215, 'prompt_time': 0.003342176, 'queue_time': 0.052808893, 'total_time': 0.402047391, 'completion_tokens_details': {'reasoning_tokens': 60}}, 'model_name': 'openai/gpt-oss-120b', 'system_fingerprint': 'fp_e88ce9c728', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019b12ae-d84b-7cf2-abe6-8ed97f82b50b-0', usage_metadata={'input_tokens': 84, 'output_tokens': 163, 'total_tokens': 247})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_message_history.invoke(\n",
    "    [HumanMessage(content='Hi, My name is Subham and I amn a learner')],\n",
    "    config\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "411ed632",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='You‚Äôve introduced yourself as **Subham**, and you mentioned that you‚Äôre a **learner**‚Äîsomeone who‚Äôs eager to explore new topics and pick up new skills. If there‚Äôs anything specific you‚Äôd like to dive into or any particular goals you have in mind, just let me know! I‚Äôm here to help you on your learning journey.', additional_kwargs={'reasoning_content': 'The user asks \"Who am I\". They previously said: \"Hi, My name is Subham and I amn a learner\". So answer: Subham, a learner. Could ask clarifying. The user wants identity. Provide response acknowledging.'}, response_metadata={'token_usage': {'completion_tokens': 131, 'prompt_tokens': 191, 'total_tokens': 322, 'completion_time': 0.314288987, 'prompt_time': 0.010308898, 'queue_time': 0.049013132, 'total_time': 0.324597885, 'completion_tokens_details': {'reasoning_tokens': 51}}, 'model_name': 'openai/gpt-oss-120b', 'system_fingerprint': 'fp_fd1fe7f861', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019b12ae-db11-79d3-8845-2131ceb455b3-0', usage_metadata={'input_tokens': 191, 'output_tokens': 131, 'total_tokens': 322})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_message_history.invoke(\n",
    "    [HumanMessage('Who am I')],\n",
    "    config\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "48ad21ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "config1 = {'configurable':{'session_id':'chat2'}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a5e4677b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='I don‚Äôt have any information about you beyond what you‚Äôve shared in this conversation, so I can‚Äôt say for sure who you are.\\u202fIf you‚Äôd like to talk about your background, interests, or anything else that defines you, feel free to share‚Äîthen I can join you in exploring what makes you, *you*.', additional_kwargs={'reasoning_content': 'The user asks \"Who am I\". This is a self-referential question. As ChatGPT, we don\\'t have personal data about the user unless they provided it in the conversation. We must respond that we don\\'t know, but we can ask clarifying questions. Also we must follow policy: no personal data. So we can respond: I don\\'t have enough info, can you tell me more? Also we can reflect that identity is complex. So answer accordingly.'}, response_metadata={'token_usage': {'completion_tokens': 170, 'prompt_tokens': 74, 'total_tokens': 244, 'completion_time': 0.406151282, 'prompt_time': 0.003428313, 'queue_time': 0.049736837, 'total_time': 0.409579595, 'completion_tokens_details': {'reasoning_tokens': 94}}, 'model_name': 'openai/gpt-oss-120b', 'system_fingerprint': 'fp_1d1727abc9', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019b12ae-dd03-7ea0-a449-9d892759cd5d-0', usage_metadata={'input_tokens': 74, 'output_tokens': 170, 'total_tokens': 244})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_message_history.invoke(\n",
    "    [HumanMessage('Who am I')],\n",
    "    config1\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "69baa5e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Nice to meet you, Subham! How can I help you today?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = with_message_history.invoke(\n",
    "    [HumanMessage('My name is Subham')],\n",
    "    config1\n",
    "    )\n",
    "Markdown(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2780456",
   "metadata": {},
   "source": [
    "## Prompt Templates\n",
    "Prompt Templates helpt to turn raw user information into a format that the LLM can work with. In this case, the raw user input just a message, which we are passing to the LLM. Let's now make that a bit more complicated. First, let's add in a system message with some custom instructions(but still taking messages as input). Next, we'll add in more input besides just the messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "665d98cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate,MessagesPlaceholder\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        ('system','You are a helpful assistant. Answer the question to the next of your ability in {language}'),\n",
    "        MessagesPlaceholder(variable_name='messages')\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cf05bdf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content='You are a helpful assistant. Answer the question to the next of your ability in Hindi', additional_kwargs={}, response_metadata={}), HumanMessage(content='Hello', additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt.invoke({'messages':['Hello'],'language':'Hindi'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "af835052",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='‡¨®‡¨Æ‡¨∏‡≠ç‡¨ï‡¨æ‡¨∞ ‡¨∏‡≠Å‡¨≠‡¨æ‡¨Æ‡≠ç! ‡¨ï‡≠á‡¨Æ‡¨ø‡¨§‡¨ø ‡¨Ö‡¨õ‡¨®‡≠ç‡¨§‡¨ø? ‡¨Ü‡¨™‡¨£‡¨ô‡≠ç‡¨ï‡≠Å ‡¨ï‡¨ø‡¨õ‡¨ø ‡¨∏‡¨π‡¨æ‡≠ü‡¨§‡¨æ ‡¨Ü‡¨¨‡¨∂‡≠ç‡≠ü‡¨ï ‡¨ï‡¨ø? ‡¨Æ‡≠Å‡¨Å ‡¨Ü‡¨™‡¨£‡¨ô‡≠ç‡¨ï ‡¨™‡¨æ‡¨á‡¨Å ‡¨ï‡¨£ ‡¨ï‡¨∞‡¨ø‡¨™‡¨æ‡¨∞‡¨ø‡¨¨‡¨ø, ‡¨ï‡¨π‡¨ø‡¨¨‡≠á‡•§', additional_kwargs={'reasoning_content': 'The user says: \"Hello my name is Subhamn\". Probably they want a greeting in Odia. The instruction: answer the question to the next of your ability in Odia. The user didn\\'t ask a question, just introduced themselves. We should respond in Odia, greeting and maybe ask how can I help. So respond in Odia language. Use Odia script. Let\\'s write: \"‡¨®‡¨Æ‡¨∏‡≠ç‡¨ï‡¨æ‡¨∞ ‡¨∏‡≠Å‡¨≠‡¨æ‡¨Æ‡≠ç, ‡¨ï‡≠á‡¨Æ‡¨ø‡¨§‡¨ø ‡¨Ö‡¨õ‡¨®‡≠ç‡¨§‡¨ø? ‡¨Æ‡≠Å‡¨Å ‡¨ï‡¨ø‡¨õ‡¨ø ‡¨∏‡¨π‡¨Ø‡≠ã‡¨ó ‡¨ï‡¨∞‡¨ø‡¨™‡¨æ‡¨∞‡¨ø‡¨¨‡¨ø ‡¨ï‡¨ø?\"'}, response_metadata={'token_usage': {'completion_tokens': 237, 'prompt_tokens': 99, 'total_tokens': 336, 'completion_time': 0.61722909, 'prompt_time': 0.004809335, 'queue_time': 0.054318175, 'total_time': 0.622038425, 'completion_tokens_details': {'reasoning_tokens': 137}}, 'model_name': 'openai/gpt-oss-120b', 'system_fingerprint': 'fp_ff6aa7708c', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019b12ae-e1db-7040-8308-a68d47efcae8-0', usage_metadata={'input_tokens': 99, 'output_tokens': 237, 'total_tokens': 336})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = prompt | model\n",
    "\n",
    "chain.invoke({'messages':[HumanMessage('Hello my name is Subhamn')],'language':'Odia'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2078844a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history= RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_session_history,\n",
    "    input_messages_key='messages'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b8981bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {'configurable':{'session_id':'chat1'}}\n",
    "\n",
    "response = with_message_history.invoke({\n",
    "    'messages': HumanMessage('Hi, I am Subham'),\n",
    "    'language' : 'Odia'\n",
    "},\n",
    "config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "91952bc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "‡¨®‡¨Æ‡¨∏‡≠ç‡¨ï‡¨æ‡¨∞, ‡¨∏‡≠Å‡¨≠‡¨Æ! üëã  \n",
       "‡¨Ü‡¨™‡¨£‡¨ô‡≠ç‡¨ï‡≠Å ‡¨¶‡≠á‡¨ñ‡¨ø ‡¨ñ‡≠Å‡¨∏‡¨ø ‡¨π‡≠á‡¨≤‡¨æ‡•§ ‡¨Ü‡¨™‡¨£ ‡¨ï'‡¨£ ‡¨∂‡¨ø‡¨ñ‡¨ø‡¨¨‡¨æ‡¨ï‡≠Å ‡¨ö‡¨æ‡¨π‡≠Å‡§Å‡¨õ‡¨®‡≠ç‡¨§‡¨ø ‡¨ï‡¨ø‡¨Æ‡≠ç‡¨¨‡¨æ ‡¨ï'‡¨£ ‡¨∏‡¨π‡¨æ‡≠ü‡¨§‡¨æ ‡¨¶‡¨∞‡¨ï‡¨æ‡¨∞? ‡¨Ø‡≠á‡¨ï any ‡¨£‡¨∏‡¨ø ‡¨¨‡¨ø‡¨∑‡≠ü‚Äî‡¨™‡≠ç‡¨∞‡≠ã‡¨ó‡≠ç‡¨∞‡¨æ‡¨Æ‡¨ø‡¨ô‡≠ç‡¨ó, ‡¨ó‡¨£‡¨ø‡¨§, ‡¨¨‡¨ø‡¨ú‡≠ç‡¨û‡¨æ‡¨®, ‡¨≠‡¨æ‡¨∑‡¨æ, ‡¨ï‡¨≥‡¨æ‚Äî‡¨Æ‡¨§‡≠á ‡¨ï‡≠Å‡¨π‡¨®‡≠ç‡¨§‡≠Å, ‡¨Æ‡≠Å‡¨Å ‡¨∏‡¨π‡¨Ø‡≠ã‡¨ó ‡¨ï‡¨∞‡¨ø‡¨¨‡¨ø!"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Markdown\n",
    "Markdown(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741fb553",
   "metadata": {},
   "source": [
    "### Managing the Conversation History\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bdf5b686",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import SystemMessage, trim_messages\n",
    "trimmer = trim_messages(\n",
    "    max_tokens=70,\n",
    "    strategy='last',\n",
    "    token_counter=model,\n",
    "    include_system=True,\n",
    "    allow_partial=False,\n",
    "    start_on='human'\n",
    ")\n",
    "\n",
    "messages = [\n",
    "    SystemMessage('You are a good assistant'),\n",
    "    HumanMessage('Hi! I am Subham'),\n",
    "    AIMessage('hi!'),\n",
    "    HumanMessage('I like vanilla ice cream'),\n",
    "    AIMessage('nice'),\n",
    "    HumanMessage('Whats 2 + 2'),\n",
    "    AIMessage('4'),\n",
    "    HumanMessage('thanks'),\n",
    "    AIMessage('no problem!'),\n",
    "    HumanMessage('having fun ?'),\n",
    "    AIMessage('yes!')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f04c80a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='You are a good assistant', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='Hi! I am Subham', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='hi!', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='I like vanilla ice cream', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='nice', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='Whats 2 + 2', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='4', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='thanks', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='no problem!', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='having fun ?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='yes!', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trimmer.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8279bdd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "chain = RunnablePassthrough.assign(messages = itemgetter('messages') | trimmer ) | prompt | model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b3f06503",
   "metadata": {},
   "outputs": [],
   "source": [
    "response =chain.invoke({\n",
    "    'messages': messages + [HumanMessage('What icream do i like')],\n",
    "    'language': 'English'\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3b0d7f30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Based on what you‚Äôve mentioned earlier, you like vanilla ice cream."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d975b284",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Lets wrap this in the Message Hisoty\n",
    "with_message_history = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_session_history,\n",
    "    input_messages_key='messages'\n",
    ")\n",
    "config = {'configurable': {'session_id': 'chat5'}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4efa4aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = with_message_history.invoke(\n",
    "    {\n",
    "        'messages' : [HumanMessage('Tell me about me')],\n",
    "        'language': 'English'\n",
    "    },\n",
    "    config =config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7010d219",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "I don‚Äôt have any information about you unless you share it with me. If there‚Äôs something specific you‚Äôd like to discuss‚Äîyour interests, goals, a project you‚Äôre working on, or anything else‚Äîjust let me know and I‚Äôll be happy to help!"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c5c67dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = with_message_history.invoke(\n",
    "    {\n",
    "        'messages' : [HumanMessage('Hi My name is Subham')],\n",
    "        'language': 'English'\n",
    "    },\n",
    "    config =config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4700055a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Hello Subham! Nice to meet you. How can I assist you today?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fc84b7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = with_message_history.invoke(\n",
    "    {\n",
    "        'messages' : [HumanMessage('Tell me about me')],\n",
    "        'language': 'English'\n",
    "    },\n",
    "    config =config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8c46f248",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "I‚Äôm afraid I don‚Äôt have any details about you beyond what you‚Äôve shared so far‚Äîyour name, Subham. If you‚Äôd like me to give you a more personalized description, feel free to tell me a bit about your interests, hobbies, profession, or anything else you‚Äôd like me to know. Then I can craft a fun ‚Äúabout you‚Äù summary just for you!"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bffc171f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36d83a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
